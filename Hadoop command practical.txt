HDFS COMMANDS
1.	copyFromLocal(Copy a file or directory from Local to HDFS)
hadoop fs –copyFromLocal /home/cloudera/sjc2019linux/f1.txt  /user/cloudera/sjc2019hadoop/
Note: Can be used for copying multiple files, similar pattern files, all the files, a directory


2.	moveFromLocal(move a file or directory from Local to HDFS)
hadoop fs –moveFromLocal /home/cloudera/sjc2019linux/f1.txt  /user/cloudera/sjc2019hadoop/

3.	copyToLocal(Copy a file or directory from HDFS to Local)
hadoop fs –copyToLocal /user/cloudera/sjc2019hadoop/f1.txt  /home/cloudera/sjc2019linux

4.	moveToLocal(Not yet implemented)

5.	cp (copy a file from one location to another location inside HDFS)
hadoop fs –cp /user/cloudera/sjc2019hadoop/file1 /user/cloudera/sjc2019hadoop/1

6.	mv (move a file from one location to another location inside HDFS)
hadoop fs –mv /user/cloudera/sjc2019hadoop/file1 /user/cloudera/sjc2019hadoop/1

7.	put (Similar to copyFromLocal)
hadoop fs –put /home/cloudera/sjc2019linux/file1  /user/cloudera/sjc2019hadoop/

8.	get (Similar to copyToLocal)
hadoop fs –get /user/cloudera/sjc2019hadoop/file1  /home/cloudera/sjc2019linux

9.	getmerge (writes multiple file contents in to a single file in Local File system)
10.	
hadoop fs –getmerge /user/cloudera/sjc2019hadoop/file1 /user/cloudera/sjc2019hadoop//file2 /home/cloudera/sjc2019linux/f3
Note : This command is not supported in this version of Hadoop.

11.	mkdir (Create a directory)
hadoop fs –mkdir  /user/cloudera/sjc2019hadoop/

12.	touchz ( can create n no: of empty files in HDFS)
hadoop fs –touchz /user/cloudera/sjc2019hadoop/file1

13.	rm (Remove a file)
hadoop fs –rm /user/cloudera/sjc2019hadoop/file1

14.	rmr (Can be used for removing a file or Directory recursively)
hadoop fs –rmr /user/cloudera/sjc2019hadoop/file
hadoop fs –rmr /user/cloudera/sjc2019hadoop/Dir1
Note: Can be used to remove similar pattern files(*.sh, *.txt etc), all the files(*)

15.	ls (Lists all the files & directories)
hadoop fs –ls /user/cloudera/sjc2019hadoop/
ls|tail –n (Tail option with List)
hadoop fs –ls /user/cloudera/sjc2019hadoop/|tail -10

16.	ls|head –n (head option with List)
hadoop fs –ls /user/cloudera/sjc2019hadoop/|head -10

17.	cat (Displays the content of a file)
hadoop fs -cat /user/cloudera/sjc2019hadoop/file

18.	text(Displays the content of zipped files)
hadoop fs -text /user/cloudera/sjc2019hadoop/file.gz

19.	cat|tail –n (Display bottom n lines of a file)
hadoop fs -cat /user/cloudera/sjc2019hadoop/file|tail 10

20.	cat|head –n (Display top n lines of a file)
hadoop fs -cat /user/cloudera/sjc2019hadoop/file|head 10

21.	cat|wc –l (Counts the no:of lines in a file)
hadoop fs -cat /user/cloudera/sjc2019hadoop/file1|wc –l

22.	cat|wc –w (Counts the no:of words in a file)
hadoop fs –cat /user/cloudera/sjc2019hadoop/file1|wc –w

23.	cat|wc –c (Counts the no:of Characters in a file)
hadoop fs -cat /user/cloudera/sjc2019hadoop/file1|wc –c

24.	du (Disk Usage of a file or directory)
hadoop fs –du /user/cloudera/sjc2019hadoop/file1.txt

25.	du –h (formats & shows file or directory size in human readable format)
hadoop fs –du -h /user/cloudera/sjc2019hadoop/

26.	du –s(shows summary of the directories instead of each file)
hadoop fs –du –s /user/cloudera/sjc2019hadoop/

0./;’[=-df
O/P: 
Filesystem                      Size             Used        Available  Use%
hdfs://nameservice1  328040332591104  102783556870823  210750795833344   31%



27.	df –h (Formats & shows in the human readable format)
hadoop fs -df –h
O/P:
Filesystem              Size    Used  Available  Use%
hdfs://nameservice1  298.4 T  93.5 T    191.7 T   31%

28.	count(Counts all the Directories & Files in the given path)
hadoop fs –count /user/cloudera/sjc2019hadoop/

29.	fsck (To check file system health)
hadoop fsck /user/cloudera/sjc2019hadoop/

30.	fsck –files –blocks (Displays corresponding Files& their block level info)
hadoop fsck /user/cloudera/sjc2019hadoop/file1.txt –files -blocks

31.	fsck –files –blocks –locations (Displays files& block level info including the block location)
32.	hadoop fsck /user/cloudera/sjc2019hadoop/f1.txt –files –blocks –locations -racks

33.	setrep(used to change the replication factor a file or a directory)
hadoop fs –setrep 5 /user/cloudera/sjc2019hadoop/file1
Hadoop fs –setrep 5 –w /user/cloudera/sjc2019hadoop/ABC
-w  It requests that the command waits for the replication to complete. This
      can potentially take a very long time.

34.	Controlling block size at file level without changing the block size in hdfs-site.xml
Hadoop fs –D dfs.block.size=134217728 –put source_path destination_path

35.	Controlling replication at file level irrespective of the default replication set to 3
Hadoop fs –D dfs.replication=2 –put source_path destination_path
36.	Setting replication factor for a directory in HDFS
Hadoop fs –setrep 5 –R /user/cloudera/sjc2019hadoop/ABC
Note: All the files copied under this directory will be having a replication factor of 5 irrespective of the default replication set.
37.	Safe Mode
Hadoop dfsadmin –safemode leave
Hadoop dfsadmin –safemode enter
Hadoop dfsadmin –safemode get
38.	Delete all the files in trash
hadoop fs -expunge


39.	Copying a file from one cluster to another cluster
hadoop fs -distcp hdfs://namenodeA/emp.csv hdfs://namenodeB/
